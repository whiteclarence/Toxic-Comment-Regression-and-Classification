{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from tqdm import tqdm\n",
    "#Feature Engineering Models\n",
    "from gensim.models import Word2Vec  ## We are importing python function for training a word2vec model.\n",
    "\n",
    "# Preparing the dataset\n",
    "from sklearn.model_selection import train_test_split   # split the dataset into training and testing set\n",
    "from sklearn.model_selection import cross_val_score    # Perform cross validation \n",
    "from sklearn.model_selection import StratifiedKFold    # Stratify the data in each fold\n",
    "from sklearn.model_selection import KFold \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import classification_report     # to get the performance measures\n",
    "from sklearn.metrics import confusion_matrix          # To compute the false positives and false negatives\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score            # Accuracy measures\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2750b-1f49-4020-80b5-b586495dd214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac31554",
   "metadata": {},
   "source": [
    "## Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "train =pd.read_csv('data/df_train_spell_hash.csv')\n",
    "df = train[['target','comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222543b-f317-4744-a7ca-875e9f72732a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73640274",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_text = train['comment_text_normalized'].tolist()\n",
    "norm_text = [str(x) for x in norm_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8863397",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [x.split() for x in norm_text]\n",
    "#doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80d061",
   "metadata": {},
   "source": [
    "## Train Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v_model=Word2Vec(sentences=doc, vector_size=300, window=7, epochs=20)  ## comment this out if loading an already saved model\n",
    "w2v_model = Word2Vec.load(\"model/word2vec.model\")  ## uncomment this out if loading an already saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a97970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v_model.save(\"model/word2vec.model\") ## comment this out if loading an already saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f847d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    #print(doc)\n",
    "    try:\n",
    "        doc_vec = [word for word in doc if word in w2v_model.wv.index_to_key]\n",
    "        #print(doc)\n",
    "        return np.mean(w2v_model.wv[doc_vec], axis=0)\n",
    "    except:\n",
    "        pass\n",
    "        #print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1707de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = [document_vector(filtered_doc) for filtered_doc in tqdm(doc)]\n",
    "#word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e053b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_indices = [i for i in range(len(word_vecs)) if word_vecs[i] is None]\n",
    "error_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc22125",
   "metadata": {},
   "source": [
    "## Drop records that threw an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = [i for i in tqdm(word_vecs) if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_df = pd.DataFrame(np.array(X_train_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44db5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c374dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_w2v = train['target']\n",
    "print(len(y_train_w2v))\n",
    "y_train_w2v.drop(y_train_w2v.index[error_indices], inplace=True)\n",
    "print(len(y_train_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_df.to_csv('data/X_train_w2v.csv', index=False)\n",
    "y_train_w2v.to_csv('data/y_train_w2v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_df =pd.read_csv('data/X_train_w2v.csv')\n",
    "y_train_w2v =pd.read_csv('data/y_train_w2v.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1930fa",
   "metadata": {},
   "source": [
    "## Split the data into 2 sets: 1) Training: 80%, 2) Testing: 20% and use Random Undersampling to balance the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c7db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc72d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train_w2v = np.where(y_train_w2v >=0.5,1.,0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, Y_train_w2v, Y_test_w2v=train_test_split(X_train_w2v_df, y_train_w2v, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817467ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_over_w2v, y_over_w2v = undersample.fit_resample(X_train_w2v, Y_train_w2v)\n",
    "X_over_w2v, y_over_w2v = X_train_w2v, Y_train_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b93259",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_over_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f524c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_over_w2v, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de7d87",
   "metadata": {},
   "source": [
    "## Use 5-fold Cross Validation to evaluate the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eec3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63046fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB=XGBRegressor(n_jobs=-1)\n",
    "results = cross_val_score(XGB, X_over_w2v, y_over_w2v, cv=kfold, scoring='neg_mean_absolute_error')#, verbose=3)\n",
    "print(\"MAE: %.3f\" % (-1 * results.mean()))#*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE: %.3f\" % (-1 * results.mean()))#*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB=XGBRegressor(verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44926594",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB.fit(X_over_w2v, y_over_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bae03-01d5-4c07-b5db-a4021b98d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fd236-b081-41f1-ba3c-622b66dc066d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d4d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6cdbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ee6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(Y_test_w2v, XGB.predict(X_test_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(Y_test_w2v, XGB.predict(X_test_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(Y_test_w2v, XGB.predict(X_test_w2v), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d54b46-fd02-4c0b-9036-ca684713fd11",
   "metadata": {},
   "source": [
    "## Implementing MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea808f5-67da-431f-9d35-9da3cc29a25d",
   "metadata": {},
   "source": [
    "### Holding out 10% as a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "nn_reg2 = Sequential()\n",
    "n_hidden = 64\n",
    "n_input = X_over_w2v.shape[1]\n",
    "\n",
    "# hidden layers\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu',input_shape=(n_input,)))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn_reg2.add(Dense(units=1, activation=None))\n",
    "nn_reg2.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','rmse','mae'])\n",
    "nn_reg2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e266ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87699dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(history.history['mae'], label='Train MAE')\n",
    "ax.plot(history.history['val_mae'], label='Validation MAE')\n",
    "ax.set_title(\"MAE vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_ylim(0.0875,0.1)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee968dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('ValidationSet_LogLoss_Plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c04f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg2.evaluate(x=X_test_w2v, y=Y_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_reg2.predict(X_test_w2v)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f4671-da04-4ddc-bbbb-2b8fd4b3824c",
   "metadata": {},
   "source": [
    "### Holding out 10% as a validation set and implementing early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527eaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stoping = EarlyStopping(monitor='val_mae',\n",
    "                min_delta=5,\n",
    "                patience=20,\n",
    "                verbose=1,\n",
    "                mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg2 = Sequential()\n",
    "n_hidden = 64\n",
    "n_input = X_over_w2v.shape[1]\n",
    "\n",
    "# hidden layers\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu',input_shape=(n_input,)))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn_reg2.add(Dense(units=1, activation=None))\n",
    "nn_reg2.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','rmse','mae'])\n",
    "nn_reg2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 300\n",
    "history = nn_reg2.fit(X_over_w2v, y_over_w2v,\n",
    "epochs=n_epochs,\n",
    "batch_size=batch_size,\n",
    "validation_split=0.1,\n",
    "callbacks=[early_stoping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(history.history['mae'], label='Train MAE')\n",
    "ax.plot(history.history['val_mae'], label='Validation MAE')\n",
    "ax.set_title(\"MAE vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_ylim(0.0875,0.1)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('2 - EarlyStopping_LogLoss_Plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg2.evaluate(x=X_test_w2v, y=Y_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb658f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_reg2.predict(X_test_w2v)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef812c8-84bc-4d3b-b013-eced4d2f3952",
   "metadata": {},
   "source": [
    "### Holding out 10% as a validation set and implementing early stopping & dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e23bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg_dropout = Sequential()\n",
    "n_hidden = 64\n",
    "dropout_rate = 0.3\n",
    "\n",
    "## Dropout for input layer\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate, input_shape=(n_input,)))\n",
    "\n",
    "## Now adding four hidden layers + dropout for each of them\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu',input_shape=(n_input,)))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "nn_reg_dropout.add(Dense(units=1, activation=None))\n",
    "\n",
    "nn_reg_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg_dropout.compile(loss='mean_squared_error', optimizer='adam',\n",
    "metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7830b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 300\n",
    "early_stoping = EarlyStopping(monitor='val_mae',\n",
    "                min_delta=5,\n",
    "                patience=40,\n",
    "                verbose=1,\n",
    "                mode='auto')\n",
    "\n",
    "history = nn_reg_dropout.fit(X_over_w2v, y_over_w2v,\n",
    "                            epochs=n_epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_split=0.1,\n",
    "                            callbacks=[early_stoping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c9837",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(history.history['mae'], label='Train MAE')\n",
    "ax.plot(history.history['val_mae'], label='Validation MAE')\n",
    "ax.set_title(\"MAE vs. epochs using dropout\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c03b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('3. Dropout_LogLoss_Plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb07cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg_dropout.evaluate(x=X_test_w2v, y=Y_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8975e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_reg_dropout.predict(X_test_w2v)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a88531-97e6-4fcb-8003-4d67ddb8f225",
   "metadata": {},
   "source": [
    "## Evaluating dataset on new tweets pulled from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets =pd.read_csv('data/tweets_normalized.csv')\n",
    "#df = train[['target','comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_text = tweets['tweet_normalized'].tolist()\n",
    "norm_text = [str(x) for x in norm_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4886c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf213e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [x.split() for x in norm_text]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = [document_vector(filtered_doc) for filtered_doc in tqdm(doc)]\n",
    "word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_indices = [i for i in range(len(word_vecs)) if word_vecs[i] is None]\n",
    "error_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ac113",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tweets_w2v = [i for i in tqdm(word_vecs) if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d227cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tweets_w2v_df = pd.DataFrame(np.array(X_tweets_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f25f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tweets_w2v_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tweets_w2v_df.to_csv('data/X_tweets_w2v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tweets_w2v_df =pd.read_csv('data/X_tweets_w2v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_reg_dropout.predict(pd.DataFrame(X_tweets_w2v))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2044b-0e5a-46ec-a7cf-9516b24af60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Prediction'] = predictions\n",
    "tweets.to_csv('data/tweets_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500605df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce81ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(X_tweets_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302e2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
